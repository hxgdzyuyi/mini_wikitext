defmodule MiniWikitext.Lexer.TextTest do
  use ExUnit.Case, async: true

  alias MiniWikitext.Lexer

  describe "text_rule æµ‹è¯•" do
    test "åŸºæœ¬æ–‡æœ¬åŒ¹é… - æ™®é€šå­—ç¬¦" do
      # æµ‹è¯•åŸºæœ¬çš„æ–‡æœ¬å­—ç¬¦ä¸²åŒ¹é…
      lexer = Lexer.new("hello world")
      {token, lexer2} = Lexer.advance(lexer)

      assert token.type == :text
      assert token.raw == "hello world"
      assert token.lineno == 1
      assert token.column == 1

      # æ£€æŸ¥å‰©ä½™å†…å®¹ä¸ºç©º
      assert lexer2.str == ""
    end

    test "ä¸­æ–‡æ–‡æœ¬åŒ¹é…" do
      # æµ‹è¯•ä¸­æ–‡å­—ç¬¦çš„åŒ¹é…
      lexer = Lexer.new("ä½ å¥½ä¸–ç•Œ")
      {token, _lexer} = Lexer.advance(lexer)

      assert token.type == :text
      assert token.raw == "ä½ å¥½ä¸–ç•Œ"
      assert token.lineno == 1
      assert token.column == 1
    end

    test "æ•°å­—å’Œå­—æ¯æ··åˆæ–‡æœ¬" do
      # æµ‹è¯•æ•°å­—ã€å­—æ¯ã€ç¬¦å·çš„æ··åˆæ–‡æœ¬
      lexer = Lexer.new("abc123def456")
      {token, _lexer} = Lexer.advance(lexer)

      assert token.type == :text
      assert token.raw == "abc123def456"
    end

    test "åŒ…å«å…è®¸çš„ç‰¹æ®Šå­—ç¬¦" do
      # æµ‹è¯•åŒ…å«å…è®¸çš„ç‰¹æ®Šå­—ç¬¦ï¼ˆä¸åœ¨æ’é™¤åˆ—è¡¨ä¸­çš„å­—ç¬¦ï¼‰
      lexer = Lexer.new("text with spaces and punctuation.,;:?")
      {token, _lexer} = Lexer.advance(lexer)

      assert token.type == :text
      assert token.raw == "text with spaces and punctuation.,;:?"
    end

    test "é‡åˆ°æ¢è¡Œç¬¦æ—¶åœæ­¢" do
      # æµ‹è¯•é‡åˆ°æ¢è¡Œç¬¦æ—¶æ–‡æœ¬åŒ¹é…åœæ­¢
      lexer = Lexer.new("hello\nworld")
      {token, lexer2} = Lexer.advance(lexer)

      assert token.type == :text
      assert token.raw == "hello"
      assert lexer2.str == "\nworld"
    end

    test "é‡åˆ° < å­—ç¬¦æ—¶åœæ­¢" do
      # æµ‹è¯•é‡åˆ° < å­—ç¬¦æ—¶æ–‡æœ¬åŒ¹é…åœæ­¢
      lexer = Lexer.new("text<tag>")
      {token, lexer2} = Lexer.advance(lexer)

      assert token.type == :text
      assert token.raw == "text"
      assert lexer2.str == "<tag>"
    end

    test "é‡åˆ°æ–¹æ‹¬å·æ—¶åœæ­¢" do
      # æµ‹è¯•é‡åˆ° [ æˆ– ] å­—ç¬¦æ—¶æ–‡æœ¬åŒ¹é…åœæ­¢
      lexer = Lexer.new("text[link]")
      {token, lexer2} = Lexer.advance(lexer)

      assert token.type == :text
      assert token.raw == "text"
      assert lexer2.str == "[link]"

      # æµ‹è¯•å³æ–¹æ‹¬å·
      lexer3 = Lexer.new("text]end")
      {token3, lexer4} = Lexer.advance(lexer3)

      assert token3.type == :text
      assert token3.raw == "text"
      assert lexer4.str == "]end"
    end

    test "é‡åˆ°èŠ±æ‹¬å·æ—¶åœæ­¢" do
      # æµ‹è¯•é‡åˆ° { æˆ– } å­—ç¬¦æ—¶æ–‡æœ¬åŒ¹é…åœæ­¢
      lexer = Lexer.new("text{template}")
      {token, lexer2} = Lexer.advance(lexer)

      assert token.type == :text
      assert token.raw == "text"
      assert lexer2.str == "{template}"

      # æµ‹è¯•å³èŠ±æ‹¬å·
      lexer3 = Lexer.new("text}end")
      {token3, lexer4} = Lexer.advance(lexer3)

      assert token3.type == :text
      assert token3.raw == "text"
      assert lexer4.str == "}end"
    end

    test "é‡åˆ°ç®¡é“ç¬¦æ—¶åœæ­¢" do
      # æµ‹è¯•é‡åˆ° | å­—ç¬¦æ—¶æ–‡æœ¬åŒ¹é…åœæ­¢
      lexer = Lexer.new("text|pipe")
      {token, lexer2} = Lexer.advance(lexer)

      assert token.type == :text
      assert token.raw == "text"
      assert lexer2.str == "|pipe"
    end

    test "é‡åˆ°æ„Ÿå¹å·æ—¶åœæ­¢" do
      # æµ‹è¯•é‡åˆ° ! å­—ç¬¦æ—¶æ–‡æœ¬åŒ¹é…åœæ­¢
      lexer = Lexer.new("text!exclamation")
      {token, lexer2} = Lexer.advance(lexer)

      assert token.type == :text
      assert token.raw == "text"
      assert lexer2.str == "!exclamation"
    end

    test "é‡åˆ°å•å¼•å·æ—¶åœæ­¢" do
      # æµ‹è¯•é‡åˆ° ' å­—ç¬¦æ—¶æ–‡æœ¬åŒ¹é…åœæ­¢
      lexer = Lexer.new("text'quote")
      {token, lexer2} = Lexer.advance(lexer)

      assert token.type == :text
      assert token.raw == "text"
      assert lexer2.str == "'quote"
    end

    test "é‡åˆ°ç­‰å·æ—¶åœæ­¢" do
      # æµ‹è¯•é‡åˆ° = å­—ç¬¦æ—¶æ–‡æœ¬åŒ¹é…åœæ­¢
      lexer = Lexer.new("text=equals")
      {token, lexer2} = Lexer.advance(lexer)

      assert token.type == :text
      assert token.raw == "text"
      assert lexer2.str == "=equals"
    end

    test "å•ä¸ªç‰¹æ®Šå­—ç¬¦çš„å›é€€å¤„ç†" do
      # æµ‹è¯•å½“é‡åˆ°å•ä¸ªç‰¹æ®Šå­—ç¬¦æ—¶ï¼Œè¿”å›è¯¥å­—ç¬¦ä½œä¸º text token
      special_chars = ["<", "[", "{", "|", "!", "'"]

      for char <- special_chars do
        lexer = Lexer.new(char)
        {token, lexer2} = Lexer.advance(lexer)

        assert token.type == :text
        assert token.raw == char
        assert lexer2.str == ""
      end
    end

    test "å•ä¸ªç‰¹æ®Šå­—ç¬¦åè·Ÿå…¶ä»–å†…å®¹" do
      # æµ‹è¯•å•ä¸ªç‰¹æ®Šå­—ç¬¦åé¢è¿˜æœ‰å…¶ä»–å†…å®¹çš„æƒ…å†µ
      lexer = Lexer.new("<hello")
      {token, lexer2} = Lexer.advance(lexer)

      assert token.type == :text
      assert token.raw == "<"
      assert lexer2.str == "hello"
    end

    test "ç©ºå­—ç¬¦ä¸²è¿”å› eos" do
      # æµ‹è¯•ç©ºå­—ç¬¦ä¸²æ—¶è¿”å› :eof token
      lexer = Lexer.new("")
      {token, _lexer} = Lexer.advance(lexer)

      # æ³¨æ„ï¼šæ ¹æ®ä»£ç å®ç°ï¼Œç©ºå­—ç¬¦ä¸²åœ¨ text_rule ä¸­è¿”å› :eosï¼Œä½†åœ¨ advance ä¸­ä¼šè¢« eos_rule æ•è·è¿”å› :eof
      assert token.type == :eof
    end

    test "å¤šå­—èŠ‚ UTF-8 å­—ç¬¦å¤„ç†" do
      # æµ‹è¯•å¤šå­—èŠ‚ UTF-8 å­—ç¬¦çš„æ­£ç¡®å¤„ç†
      lexer = Lexer.new("ğŸ˜€ğŸ‰ä¸­æ–‡æµ‹è¯•")
      {token, _lexer} = Lexer.advance(lexer)

      assert token.type == :text
      assert token.raw == "ğŸ˜€ğŸ‰ä¸­æ–‡æµ‹è¯•"
    end

    test "å•ä¸ªå¤šå­—èŠ‚å­—ç¬¦çš„å›é€€å¤„ç†" do
      # æµ‹è¯•å•ä¸ªå¤šå­—èŠ‚å­—ç¬¦åœ¨ç‰¹æ®Šæƒ…å†µä¸‹çš„å¤„ç†
      lexer = Lexer.new("ğŸ˜€<tag>")
      {token, lexer2} = Lexer.advance(lexer)

      assert token.type == :text
      assert token.raw == "ğŸ˜€"
      assert lexer2.str == "<tag>"
    end

    test "ä½ç½®ä¿¡æ¯æ­£ç¡®è®¾ç½®" do
      # æµ‹è¯• token çš„è¡Œå·å’Œåˆ—å·ä¿¡æ¯æ­£ç¡®è®¾ç½®
      lexer = Lexer.new("hello")
      {token, _lexer} = Lexer.advance(lexer)

      assert token.lineno == 1
      assert token.column == 1
    end

    test "åŒ…å«åˆ¶è¡¨ç¬¦å’Œç©ºæ ¼çš„æ–‡æœ¬" do
      # æµ‹è¯•åŒ…å«åˆ¶è¡¨ç¬¦å’Œç©ºæ ¼çš„æ–‡æœ¬
      lexer = Lexer.new("hello\tworld with spaces")
      {token, _lexer} = Lexer.advance(lexer)

      assert token.type == :text
      assert token.raw == "hello\tworld with spaces"
    end
  end
end
